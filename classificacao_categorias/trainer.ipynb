{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import re\r\n",
    "import pickle \r\n",
    "import sqlite3 as sl\r\n",
    "from unicodedata import normalize\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "import nltk\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.naive_bayes import BernoulliNB\r\n",
    "from scipy import sparse\r\n",
    "import numpy as np\r\n",
    "nltk.download('stopwords')\r\n",
    "con = sl.connect('../coleta_de_dados/banco_scraping_olx.db')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ANACLARASAMARINO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def normaliza_texto_vetorizado(text:str)->str: \r\n",
    "    \"\"\"\r\n",
    "    função criada para transformar os títulos dos anuncios em um formato padronizado, sem caracteres especiais e sem números\r\n",
    "    \"\"\"\r\n",
    "    frase_minuscula = normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII').lower() #normaliza para retirar acentos e transforma para minuscula\r\n",
    "    somente_palavras_validas = re.sub(\"([^\\w]+)|((\\w|d)*[\\d](\\w|d)*)\",\" \",frase_minuscula) #substitui a string acima por uma string sem numeros e sem caracteres especiais\r\n",
    "    texto_normalizado = re.sub(\"\\s+\",\" \",somente_palavras_validas).strip() #substitui um ou mais espaços da string acima por um único espaço\r\n",
    "    return texto_normalizado.split(\" \") #retorna uma lista com as palavras válidas "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "todos_titulos = pd.read_sql(\"\"\"\r\n",
    "SELECT DISTINCT \r\n",
    "\turl_anuncio,\t\r\n",
    "\ttitulo_anuncio\t\r\n",
    "FROM\r\n",
    "\tanuncios_resumo\r\n",
    "\"\"\", con, chunksize=1000000)\r\n",
    "#pega as urls dos anuncios e os títulos (considerando apenas distintos) no banco de dados. Chuncksize para pegar por partes para não estourar memória "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def constroi_dicionario_palavras(df_pandas_chunked,dicionario):\r\n",
    "    \"\"\" \r\n",
    "    Função para construir o dicionário com as palavras dos títulos dos anúncios e adicionar a quantidade referente a cada palavra\r\n",
    "    \"\"\"    \r\n",
    "    qt_linhas_processadas = 0\r\n",
    "    for df in df_pandas_chunked: #para cada subdivisão gerada pelo chunked\r\n",
    "        qt_linhas_processadas += len(df) #salva em uma variável a qtd de linhas já processadas\r\n",
    "        print(f\"qt linhas processadas: {qt_linhas_processadas}\") #imprime a qtd de linhas processadas até então\r\n",
    "        for titulo in df['titulo_anuncio']: #para cada título nos títulos retornadas, segue\r\n",
    "            titulo_vetorizado = normaliza_texto_vetorizado(titulo) #normaliza o título e transforma em uma lista de palavras\r\n",
    "            for palavras_titulo in titulo_vetorizado: #para cada palavra no título,\r\n",
    "                if palavras_titulo: #se palavras_titulo for válida, segue\r\n",
    "                    if dicionario.get(palavras_titulo): #verifica se existe palavras_titulo no dicionário\r\n",
    "                        dicionario[palavras_titulo]+=1 #soma 1 unidade ao valor correspondente à chave palavras_titulo\r\n",
    "                    else:\r\n",
    "                        dicionario[palavras_titulo]=1 #se não tiver a chave no dicionário, adiciona e atribui 1 unidade para ela"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def filtrar_dicionario(dicionario_palavras,qtd_minima_palavras_usadas = 5):\r\n",
    "    \"\"\" \r\n",
    "    Função para filtrar o dicionário retirando todas as preposições e artigos e palavras com menos de 3 letras, e pegando apenas as palavras com mais repetições do que informado como parâmetro\r\n",
    "    \"\"\" \r\n",
    "    artigos_preposicoes = stopwords.words('portuguese') #pega uma lista de palavras em portugues da biblioteca nltk.corpus\r\n",
    "    todas_chaves = dicionario_palavras.keys() #guarda as chaves do dicionário em uma lista\r\n",
    "    chaves_para_excluir=[] #lista com as chaves para excluir do dicionário\r\n",
    "    for chave in todas_chaves: \r\n",
    "        if chave in artigos_preposicoes or dicionario_palavras[chave] < qtd_minima_palavras_usadas or len(chave)<3:\r\n",
    "            chaves_para_excluir.append(chave) #se a palavra for preposição/artigo, ou tiver menos do que o limite determinado no parâmetro ou tiver menos de 3 letras,\r\n",
    "    for chave_ex in chaves_para_excluir: #adiciona a palavra na lista para deleção\r\n",
    "        del dicionario_palavras[chave_ex] #deleta do dicionário todas as chaves que estão na lista para deleção"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "dicionario_todas_palavras = {}\r\n",
    "\r\n",
    "if not Path('./dicionario_todas_palavras.pkl').is_file(): #se o caminho indicado não for um arquivo\r\n",
    "    constroi_dicionario_palavras(todos_titulos,dicionario_todas_palavras) #constroi o dicionario \r\n",
    "    filtrar_dicionario(dicionario_todas_palavras,30) #filtra o dicionário conforme descrição da função filtrar_dicionario \r\n",
    "    with open('./dicionario_todas_palavras.pkl', 'wb') as file: #cria um arquivo para escrita e abre para escrita\r\n",
    "        pickle.dump(dicionario_todas_palavras, file) #coloca a variável(dicionario) no arquivo\r\n",
    "else : #se o caminho indicado for um arquivo,\r\n",
    "    with open('./dicionario_todas_palavras.pkl', 'rb') as file: #abrir para leitura\r\n",
    "        dicionario_todas_palavras = pickle.load(file) #transforma arquivo em variável (dicionário), carrega e salva em dicionario_todas_palavras\r\n",
    "\r\n",
    "lista_todas_palavras = [*dicionario_todas_palavras.keys()] #transforma as chaves do dicionario em lista e salva em lista_todas_palavras     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df_todas_categorias = pd.read_sql(\"\"\"\r\n",
    "SELECT DISTINCT \r\n",
    "\tcategoria_atual\r\n",
    "FROM\r\n",
    "\tanuncios_resumo\r\n",
    "\"\"\", con) #pega todas as categorias(finais) do banco de dados\r\n",
    "lista_todas_categorias = [*df_todas_categorias['categoria_atual']] #transforma as categorias acima em uma lista e atribui a lista_todas_categorias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def categoria_para_indice(categoria,lista_todas_categorias):\r\n",
    "    \"\"\"verifica qual o índice da categoria informada conforme a lista_todas_categorias\"\"\"\r\n",
    "    if lista_todas_categorias.count(categoria): #se existir a categoria na lista,\r\n",
    "        return lista_todas_categorias.index(categoria) #retorna o indice da categoria na lista_todas_categorias\r\n",
    "    else:\r\n",
    "        return -1 #caso contrário, retorna -1\r\n",
    "        \r\n",
    "def titulo_para_indices(titulo,lista_todas_palavras): \r\n",
    "    \"\"\"verifica qual o indice \"\"\"\r\n",
    "    lista_palavras_titulo = normaliza_texto_vetorizado(titulo) #normaliza o título informado\r\n",
    "    indices_titulo =[] #lista de indices (conforme lista_todas_palavras) referentes as palavras do título\r\n",
    "    for palavra_titulo in lista_palavras_titulo: #para cada palavra na lista_palavras_titulo,\r\n",
    "        if lista_todas_palavras.count(palavra_titulo): #se existir a palavra do título na lista lista_todas_palavras, \r\n",
    "            indices_titulo.append(lista_todas_palavras.index(palavra_titulo)) #adiciona o indice da palavra(indice referente a lista_todas_palavras) na indices_titulo\r\n",
    "    return indices_titulo   #retorna uma lista com os indices do titulo              "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#testes:\r\n",
    "#categoria_para_indice('Artigos infantis',lista_todas_categorias)\r\n",
    "#titulo_para_indices('baba de cachorro com casa grande',lista_todas_palavras)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "lista_precos = [*range(10)] # coluna que irá classificar o preço (sera usado log 10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def preco_para_indice(preco,indice_start=0):\r\n",
    "    \"\"\"\r\n",
    "    Atribui um índice para um range de preços na escala log\r\n",
    "    \"\"\"\r\n",
    "    if isinstance(preco,float) or isinstance(preco,int): #se o preço for int ou float retorna true e segue\r\n",
    "        if preco>1:\r\n",
    "            index = np.ceil(np.log10(preco)) #arredonda o valor de Log(preço) na base 10 para servir como um índice\r\n",
    "            index = int(index) if index>=0 and index<len(lista_precos) else 0 #passa o indice para inteiro se indice for >= 0 e for menor do que o tamaho da lista_preços\r\n",
    "            return index+indice_start #indice_start -> começa depois do termino da matriz de palavras\r\n",
    "    return 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "def monta_sql_por_categoria(categoria):\r\n",
    "    return f\"\"\"SELECT DISTINCT \r\n",
    "                    url_anuncio,\r\n",
    "                    titulo_anuncio,\r\n",
    "                    categoria_atual,\r\n",
    "                    preco_anuncio\r\n",
    "                FROM\r\n",
    "                    anuncios_resumo\r\n",
    "                WHERE categoria_atual = '{categoria}'\r\n",
    "                --LIMIT 1000 -- Colocar um limit para testar\r\n",
    "                \"\"\"\r\n",
    "    #query para pegar url_anuncio, titulo_anuncio, categoria_atual,preco_anuncio referentes a uma categoria específicca"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "classes_y = [*range(len(lista_todas_categorias))] #cria uma lista com indices de 0 ao tamaho da lista_todas_categorias para ser índice das categorias"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "clf = BernoulliNB() # Modelo Usado (teste com Bernoulli)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "for categoria in lista_todas_categorias: \r\n",
    "    \"\"\"\r\n",
    "    Cria matriz esparsa e treina o modelo com base nela\r\n",
    "    \"\"\"\r\n",
    "    df_cat_atual = pd.read_sql(monta_sql_por_categoria(categoria),con)\r\n",
    "    print(f'Treinando Modelo para a Categoria: {categoria}')\r\n",
    "    qt_colunas = len(lista_todas_palavras)+len(lista_precos) #qtd de colunas da matriz é a soma do tamanho das duas listas\r\n",
    "    X_linhas = []\r\n",
    "    X_colunas = []\r\n",
    "    for linha in range(len(df_cat_atual)): # Adiciona valores na matrix esparsa\r\n",
    "        X_colunas_atual = titulo_para_indices(df_cat_atual['titulo_anuncio'][linha],lista_todas_palavras) #adiciona em X_colunas_atual os indices referentes as palavras\r\n",
    "        X_colunas_atual += [preco_para_indice(df_cat_atual['preco_anuncio'][linha],len(lista_todas_palavras))] #adiciona em X_colunas_atual o índice referente a coluna de preço\r\n",
    "        X_colunas+=X_colunas_atual #adiciona no vetor todos os indices das colunas utilizados\r\n",
    "        X_linhas += [linha]*len(X_colunas_atual) #preenche com o valor da linha um vetor do tamanho da coluna atual\r\n",
    "    Dados_X = np.full(len(X_linhas),1,dtype=np.int8) #retorna um array do tamanho do x_linhas preenchido com 1\r\n",
    "    X = sparse.coo_matrix((Dados_X, (X_linhas, X_colunas)), shape=(len(df_cat_atual), qt_colunas)) #matriz esparsa: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html         \r\n",
    "    Y = np.full(len(df_cat_atual),categoria_para_indice(df_cat_atual['categoria_atual'][0],lista_todas_categorias)) #preenche todo vetor Y com o nome da categoria em que irá treinar o modelo \r\n",
    "    clf.partial_fit(X,Y,classes=classes_y) #Treina o Modelo      "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Treinando Modelo para a Categoria: Aluguel - casas e apartamentos\n",
      "Treinando Modelo para a Categoria: Animais para agropecuária\n",
      "Treinando Modelo para a Categoria: Antiguidades\n",
      "Treinando Modelo para a Categoria: Aquários e acessórios\n",
      "Treinando Modelo para a Categoria: Artigos infantis\n",
      "Treinando Modelo para a Categoria: Barcos e aeronaves\n",
      "Treinando Modelo para a Categoria: Beleza e saúde\n",
      "Treinando Modelo para a Categoria: Bijouterias, relógios e acessórios\n",
      "Treinando Modelo para a Categoria: Bolsas, malas e mochilas\n",
      "Treinando Modelo para a Categoria: CDs, DVDs etc\n",
      "Treinando Modelo para a Categoria: Cachorros\n",
      "Treinando Modelo para a Categoria: Caminhões\n",
      "Treinando Modelo para a Categoria: Carros, vans e utilitários\n",
      "Treinando Modelo para a Categoria: Cavalos\n",
      "Treinando Modelo para a Categoria: Celulares e telefonia\n",
      "Treinando Modelo para a Categoria: Ciclismo\n",
      "Treinando Modelo para a Categoria: Computadores e acessórios\n",
      "Treinando Modelo para a Categoria: Comércio e indústria\n",
      "Treinando Modelo para a Categoria: Eletrodomésticos\n",
      "Treinando Modelo para a Categoria: Eletrônicos e celulares\n",
      "Treinando Modelo para a Categoria: Equipamentos e mobiliário\n",
      "Treinando Modelo para a Categoria: Esportes e ginástica\n",
      "Treinando Modelo para a Categoria: Esportes e lazer\n",
      "Treinando Modelo para a Categoria: Gatos\n",
      "Treinando Modelo para a Categoria: Hobbies e coleções\n",
      "Treinando Modelo para a Categoria: Instrumentos musicais\n",
      "Treinando Modelo para a Categoria: Lançamentos\n",
      "Treinando Modelo para a Categoria: Livros e revistas\n",
      "Treinando Modelo para a Categoria: Materiais de construção e jardim\n",
      "Treinando Modelo para a Categoria: Moda e beleza\n",
      "Treinando Modelo para a Categoria: Motos\n",
      "Treinando Modelo para a Categoria: Máquinas para produção industrial\n",
      "Treinando Modelo para a Categoria: Máquinas pesadas para construção\n",
      "Treinando Modelo para a Categoria: Móveis\n",
      "Treinando Modelo para a Categoria: Música e hobbies\n",
      "Treinando Modelo para a Categoria: Objetos de decoração\n",
      "Treinando Modelo para a Categoria: Outros animais\n",
      "Treinando Modelo para a Categoria: Outros itens para agro e indústria\n",
      "Treinando Modelo para a Categoria: Outros itens para comércio e escritório\n",
      "Treinando Modelo para a Categoria: Para a sua casa\n",
      "Treinando Modelo para a Categoria: Peças para barcos e aeronaves\n",
      "Treinando Modelo para a Categoria: Peças para caminhões\n",
      "Treinando Modelo para a Categoria: Peças para carros, vans e utilitários\n",
      "Treinando Modelo para a Categoria: Peças para motos\n",
      "Treinando Modelo para a Categoria: Peças para tratores e máquinas\n",
      "Treinando Modelo para a Categoria: Peças para ônibus\n",
      "Treinando Modelo para a Categoria: Produção Rural\n",
      "Treinando Modelo para a Categoria: Roedores\n",
      "Treinando Modelo para a Categoria: Roupas e calçados\n",
      "Treinando Modelo para a Categoria: Serviços\n",
      "Treinando Modelo para a Categoria: Temporada\n",
      "Treinando Modelo para a Categoria: Terrenos, sítios e fazendas\n",
      "Treinando Modelo para a Categoria: Trailers e carrinhos comerciais\n",
      "Treinando Modelo para a Categoria: Tratores e máquinas agrícolas\n",
      "Treinando Modelo para a Categoria: Utilidades domésticas\n",
      "Treinando Modelo para a Categoria: Vagas de emprego\n",
      "Treinando Modelo para a Categoria: Venda - casas e apartamentos\n",
      "Treinando Modelo para a Categoria: Videogames\n",
      "Treinando Modelo para a Categoria: Áudio, TV, vídeo e fotografia\n",
      "Treinando Modelo para a Categoria: Ônibus\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "def procura_categoria(titulo,preco=None,qt_impr=5):\r\n",
    "    \"\"\" \r\n",
    "    Função para testar as entradas com base no título e no preço do produto a ser cadastrado\r\n",
    "    \"\"\"\r\n",
    "    qt_colunas = len(lista_todas_palavras)+len(lista_precos) #qt de colunas da matriz\r\n",
    "    XN = sparse.dok_matrix((1, qt_colunas), dtype=np.int8) #constrói matriz esparsa XN de forma incremental\r\n",
    "    if preco:\r\n",
    "        XN[0,preco_para_indice(preco,len(lista_todas_palavras))] = 1 #popula 1 na coluna referente ao preço\r\n",
    "\r\n",
    "    indices_palavras_titulo = titulo_para_indices(titulo,lista_todas_palavras) #lista com os indices das palavras do titulo\r\n",
    "    for indice_palavra in indices_palavras_titulo: \r\n",
    "        XN[0,indice_palavra] = 1 #popula 1 nas colunas referentes às palavras do título com base nos índices de indices_palavras_titulo\r\n",
    "\r\n",
    "    categorias_prob = clf.predict_proba(XN[0]) # retorna a probabilidade referente a cada categoria\r\n",
    "    indice_categorias_ordenado = np.flip(np.argsort(categorias_prob)) #ordena os indices de acordo com a probabilidade decrescente\r\n",
    "    limite_impressoes = qt_impr #variável que define a quantidade de categorias a serem impressas\r\n",
    "    for indice_categoria in indice_categorias_ordenado.tolist()[0]:\r\n",
    "        print(f'{lista_todas_categorias[indice_categoria]}:{categorias_prob[0][indice_categoria]*100:.2f}%') #imprime uma categoria e o percentual referente a ela (ordem decrescente)\r\n",
    "        if limite_impressoes<=1:\r\n",
    "            break\r\n",
    "        limite_impressoes -=1\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "procura_categoria('blusa')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Roupas e calçados:65.11%\n",
      "Moda e beleza:28.26%\n",
      "Artigos infantis:3.92%\n",
      "Esportes e lazer:0.70%\n",
      "Beleza e saúde:0.38%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "model_add_data = {}\r\n",
    "model_add_data['lista_todas_palavras']  = lista_todas_palavras\r\n",
    "model_add_data['lista_precos'] = lista_precos\r\n",
    "model_add_data['lista_todas_categorias']= lista_todas_categorias\r\n",
    "\r\n",
    "with open('./BernoulliNB_model.pkl', 'wb') as file:\r\n",
    "    pickle.dump(clf, file)\r\n",
    "with open('./BernoulliNB_model_adds.pkl', 'wb') as file:\r\n",
    "    pickle.dump(model_add_data, file)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "56a7faacf1c4dc0f5d7b7afc61346b24d10927f5de434ccac7dd24944d9b691b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}